{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat with MySQL Database with Python | Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=RunnableAssign(mapper={\n",
      "  schema: RunnableLambda(get_schema)\n",
      "}) middle=[ChatPromptTemplate(input_variables=['question', 'schema'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question', 'schema'], input_types={}, partial_variables={}, template=\"\\nBased on the table schema below, write a SQL query that would answer the user's question:\\n{schema}\\n\\nQuestion: {question}\\nSQL Query\\n\"), additional_kwargs={})]), RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001F2E4595950>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001F2E36CA510>, root_client=<openai.OpenAI object at 0x000001F2DFCF0DD0>, root_async_client=<openai.AsyncOpenAI object at 0x000001F2E44C2910>, model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'stop': '\\nSQL Result:'}, config={}, config_factories=[])] last=StrOutputParser()\n",
      "SELECT \n",
      "    DATE_FORMAT(InvoiceDate, '%Y-%m') AS Month,\n",
      "    SUM(Total) AS TotalSales\n",
      "FROM invoice\n",
      "GROUP BY Month\n",
      "ORDER BY TotalSales DESC\n",
      "LIMIT 1;\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The best month of sales was January 2022, with a total sales amount of $52.62.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 3013, 'total_tokens': 3036, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2944}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-eb34977e-aea7-4940-a2a1-205d9c27ef44-0', usage_metadata={'input_tokens': 3013, 'output_tokens': 23, 'total_tokens': 3036, 'input_token_details': {'audio': 0, 'cache_read': 2944}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "# CHAIN RESPONSIBLE TO BUILD THE SQL QUERY BASED ON THE TABLE SCHEMA AND PROMPT\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "OPENAI_KEY = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "Based on the table schema below, write a SQL query that would answer the user's question:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt.format(schema='my schema', question=\"how many users are there?\")\n",
    "\n",
    "db_uri = \"mysql+mysqlconnector://root:password@localhost:3306/chinook\"\n",
    "db = SQLDatabase.from_uri(db_uri)\n",
    "\n",
    "def get_schema(_):\n",
    "    return db.get_table_info()\n",
    "\n",
    "get_schema(None)\n",
    "\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "sql_chain = (\n",
    "    RunnablePassthrough.assign(schema=get_schema)\n",
    "    | prompt\n",
    "    | llm.bind(stop=\"\\nSQL Result:\") #Forma de interromper a execução da LLM ao obter o resultado referente sp SQL result. Isso evita alucinações no resultado.\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "sql_chain.invoke({\"question\":\"how many artist are there?\"})\n",
    "\n",
    "print(sql_chain)\n",
    "\n",
    "template = \"\"\"\n",
    "Base on the table schema below, question, sql query, and sql response, write a natural language response:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Response: {response}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "def run_query(query):\n",
    "    print(query)\n",
    "    return db.run(query)\n",
    "\n",
    "\n",
    "full_chain = (\n",
    "    RunnablePassthrough.assign(query=sql_chain).assign(\n",
    "        schema=get_schema,\n",
    "        response= lambda variables: run_query(variables[\"query\"])\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "full_chain.invoke({\"question\":\"How was the best month of sales?\"})\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
